{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TajikDanyal/Pothole-Detection/blob/master/BRATS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN02X5lxmliy",
        "colab_type": "code",
        "outputId": "b127e871-98b6-483c-d699-e92f3674cc73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/2019/MICCAI_BraTS_2019_Data_Training.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-12 08:36:11--  https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/2019/MICCAI_BraTS_2019_Data_Training.zip\n",
            "Resolving www.cbica.upenn.edu (www.cbica.upenn.edu)... 165.123.244.124\n",
            "Connecting to www.cbica.upenn.edu (www.cbica.upenn.edu)|165.123.244.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2759083030 (2.6G) [application/zip]\n",
            "Saving to: ‘MICCAI_BraTS_2019_Data_Training.zip’\n",
            "\n",
            "MICCAI_BraTS_2019_D 100%[===================>]   2.57G  34.7MB/s    in 79s     \n",
            "\n",
            "2019-09-12 08:37:31 (33.1 MB/s) - ‘MICCAI_BraTS_2019_Data_Training.zip’ saved [2759083030/2759083030]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYb1kQKmnCKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "zip = ZipFile('MICCAI_BraTS_2019_Data_Training.zip')\n",
        "zip.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn3roiMu51l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from keras.utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs0GX9iM6Ttm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/MICCAI_BraTS_2019_Data_Training/HGG/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDktqyUW6V7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyGenerator(Sequence):\n",
        "    def __init__(self, Path, Type=\"Train\", Ratio=0.8):\n",
        "        self.Path=Path\n",
        "        self.Folders=os.listdir(Path)\n",
        "        self.Type = Type\n",
        "        self.Train, self.Test, self.Valid = Split(self.Folders, Ratio)\n",
        "    def __len__(self):\n",
        "        if self.Type is \"Train\" :\n",
        "            return len(self.Train)\n",
        "        elif self.Type is \"Test\":\n",
        "            return len(self.Test)\n",
        "        return len(self.Valid)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.Type is \"Train\" :\n",
        "            return ReadImageDataFromFolderFiles(self.Train[idx])\n",
        "        elif self.Type is \"Test\" :\n",
        "            return ReadImageDataFromFolderFiles(self.Test[idx])\n",
        "        return ReadImageDataFromFolderFiles(self.Valid[idx])\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvHjyDP6ZXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadDataset(Path):\n",
        "    return os.listdir(Path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AncRWXyJ6dUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SetLabel(FileName):\n",
        "    if\"t1.\" in FileName :\n",
        "        return \"T1\"\n",
        "    elif \"t1ce.\" in FileName:\n",
        "        return \"T1CE\"\n",
        "    elif \"seg.\" in FileName:\n",
        "        return \"Segmented\"\n",
        "    elif \"flair.\" in FileName:\n",
        "        return \"Flair\"\n",
        "    elif \"t2.\" in FileName:\n",
        "        return \"T2\"\n",
        "    return \"Undefined\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSgENb7d6fze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadImageDataFromFolderFiles(FolderName):\n",
        "    Files = os.listdir(PATH+FolderName)\n",
        "    Files.sort()\n",
        "    Images = [nib.load( PATH+FolderName+\"/\"+File ).get_fdata() for File in Files]\n",
        "    XData = np.zeros( (Images[0].shape[2], Images[0].shape[0], Images[0].shape[1], 4) )\n",
        "    YData = np.zeros( (Images[0].shape[2], Images[0].shape[0], Images[0].shape[1], 1) )\n",
        "    for i in range(Images[0].shape[2]):\n",
        "        XData[i,:,:,0] = Images[0][:,:,i]\n",
        "        XData[i,:,:,1] = Images[2][:,:,i]\n",
        "        XData[i,:,:,2] = Images[3][:,:,i]\n",
        "        XData[i,:,:,3] = Images[4][:,:,i]\n",
        "        YData[i,:,:,0] = Images[1][:,:,i]\n",
        "    return XData, YData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi25WPTp6gjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DisplaySample(FolderName, index):\n",
        "    print(\"****IN: \"+str(index+1)+\" PATH=\"+PATH+FolderName+\"****\")\n",
        "    Files = os.listdir(PATH+FolderName)\n",
        "    fig, axes = plt.subplots(1, len(Files))\n",
        "    count=0\n",
        "    TempFiles=Files\n",
        "    TempFiles.sort()\n",
        "    print(TempFiles)\n",
        "    for File in Files:\n",
        "        img = nib.load(PATH+FolderName+\"/\"+File)\n",
        "        img_data = img.get_fdata()\n",
        "        #raise ValueError(img_data.shape)\n",
        "        axes[count].title.set_text(SetLabel(File))\n",
        "        axes[count].imshow(img_data[:,:,77].T, aspect=\"equal\",  interpolation='nearest', origin=\"lower\")\n",
        "        count+=1\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvS-IhTW6mSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AnimateSample(FolderName, index):\n",
        "    print(\"****IN: \"+str(index+1)+\" PATH=\"+PATH+FolderName+\"****\")\n",
        "    Files = os.listdir(PATH+FolderName)\n",
        "    TempFiles=Files\n",
        "    TempFiles.sort()\n",
        "    for File in Files:\n",
        "        img = nib.load(PATH+FolderName+\"/\"+File)\n",
        "        img_data = img.get_fdata()\n",
        "        #raise ValueError()\n",
        "        \n",
        "        for i in range(img.shape[2]):\n",
        "            plt.imshow(img_data[:,:,i].T)\n",
        "            plt.title(File)\n",
        "            plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdUKDRUw6o2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Split(Folders, Ratio=0.8):\n",
        "    random.shuffle(Folders)\n",
        "    Train = []\n",
        "    Test = []\n",
        "    Valid = []\n",
        "    SplitPoint = int(Ratio*len(Folders))\n",
        "    Train = Folders[0:SplitPoint]\n",
        "    Test = Folders[SplitPoint:len(Folders)]\n",
        "    SplitPoint = int(Ratio*len(Train))\n",
        "    Valid = Train[SplitPoint:len(Train)]\n",
        "    Train = Train[0:SplitPoint]\n",
        "    return Train, Test, Valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go-uSYvi6rNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PreProcessAndPrepareDataset(Path):\n",
        "    Folders=ReadDataset(Path)\n",
        "    X = np.zeros((len(Folders),155*5,240,240))\n",
        "    for Folder in Folders:\n",
        "        ImageList = ReadImageDataFromFolderFiles(Folder)\n",
        "        ImageArray = np.asarray(ImageList)\n",
        "        print(ImageArray.shape)\n",
        "        ImageArray = ImageArray.reshape((155*5,240,240))\n",
        "        raise ValueError(ImageArray.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhK9uv166uR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet(pretrained_weights = None,input_size = (240, 240,4)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO5GjPcQ6yIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Folders = ReadDataset(PATH)\n",
        "#TrainGenerator = MyGenerator(PATH)\n",
        "#Model=unet()\n",
        "#Model.fit_generator(TrainGenerator, epochs=2, steps_per_epoch=259)\n",
        "for Index, Folder in enumerate(Folders):\n",
        "    AnimateSample(Folders[0], 0)\n",
        "#Train, Test, Valid = Split(Folders, 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}